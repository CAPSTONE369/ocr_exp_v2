MODEL_CFG:
  PRETRAINED: ''
  PRETRAINED_OPTIM: ''
  RES_IN: 32
  MAX_SEQ_LENGTH: 30 #75
  EMBEDDING_DIM: 512
  HEAD_NUM: !!int 8
  IMG_W: 192
  IMG_H: 32 # 128

TRAIN_CFG:
  LOSS_FN: 'CE'
  OPTIMIZER: 'ADAM'
  SCHEDULER: 'CYCLIC' # 'STEP'
  MOMENTUM: 0.9
  LR: !!float 3e-4 ## 3e-4 ## => 신기하게 ADAM은 1e-4 ~ 1e-5를 시작으로 잡는 것이, SGD는 0.1 ~ 0.01 정도를 시작 learning rate로 잡는 것이 효과적이다.
  DEBUG: !!bool false
  BATCH_SIZE: 300 
  EPOCH: !!int 100
  EVAL_EPOCH: !!int 10
  WEIGHT_FOLDER: '/home/guest/ocr_exp_v2/weight'
  OPTIM_FOLDER: '/home/guest/ocr_exp_v2/text_recognition_hangul/optim'

DATA_CFG:
  DATASET: 'HENDatasetV2'
  USE_OUTDOOR: !!bool false
  BASE_FOLDER: '/home/guest/ocr_exp_v2/data/printed_text' ## 학습을 text_recognition 폴더 내에서 시킬 것이기 때문에 
  MEAN: [0.5,0.5,0.5] # [0.0,0.0,0.0] 
  STD: [0.5,0.5,0.5] # [1.0,1.0,1.0] 
  BASE_CHARACTERS: 
    - ' ' ## 공백은 종성에 무조건 있기 때문에 꼭 포함을 시켜야 한다.
    - 'ㄱ'
    - 'ㄲ'
    - 'ㄳ'
    - 'ㄴ'
    - 'ㄵ'
    - 'ㄶ'
    - 'ㄷ'
    - 'ㄸ'
    - 'ㄹ'
    - 'ㄺ'
    - 'ㄻ'
    - 'ㄼ'
    - 'ㄽ'
    - 'ㄾ'
    - 'ㄿ'
    - 'ㅀ'
    - 'ㅁ'
    - 'ㅂ'
    - 'ㅃ'
    - 'ㅄ'
    - 'ㅅ'
    - 'ㅆ'
    - 'ㅇ'
    - 'ㅈ'
    - 'ㅉ'
    - 'ㅊ'
    - 'ㅋ'
    - 'ㅌ'
    - 'ㅍ'
    - 'ㅎ'
    - 'ㅏ'
    - 'ㅐ'
    - 'ㅑ'
    - 'ㅒ'
    - 'ㅓ'
    - 'ㅔ'
    - 'ㅕ'
    - 'ㅖ'
    - 'ㅗ'
    - 'ㅘ'
    - 'ㅙ'
    - 'ㅚ'
    - 'ㅛ'
    - 'ㅜ'
    - 'ㅝ'
    - 'ㅞ'
    - 'ㅟ'
    - 'ㅠ'
    - 'ㅡ'
    - 'ㅢ'
    - 'ㅣ'
  ADD_NUM: !!bool False
  ADD_ENG: !!bool False
  ADD_SPECIAL: !!bool False
  MAX_LENGTH: !!int 30 # 75
  IMG_H: !!int 32
  IMG_W: !!int 192 # 128
